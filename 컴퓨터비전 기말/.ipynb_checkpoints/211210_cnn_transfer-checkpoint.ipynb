{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa459ad-d2de-493a-9e30-2d6d71a287c0",
   "metadata": {},
   "source": [
    "## CNN(Convolution Neural Networks)\n",
    "- https://yjjo.tistory.com/8\n",
    "    - 시각적인 인지를 본따 만든 신경망 ~ \"공간\"에 따른 특징을 추출\n",
    "    - kernel == mask == window : 이미지의 특성값을 추출\n",
    "        - kernel size : 3x3, 5x5 ~ 이미지 크기에 변화가 생김\n",
    "    - stride : 보폭\n",
    "    - padding : kernel 연산 시 비어있는 부분을 채워 줌, 모서리 부분 정보 손실, 이미지 크기 줄어듦을 방지\n",
    "    - Convolution layer(Conv1D, Conv2D, Conv3D)\n",
    "        - kernel 계산을 통해 특징을 추출\n",
    "        - model.add(Conv2D(32, kernel_size=(3,3), input_shape=(28,28,1), activation='relu')\n",
    "    - Pooling : kernel 구역 내의 대표값 하나를 선택, 연산량을 줄여줌, 주로 MaxPooling 사용 \n",
    "    - Dropout : 과적합 방지를 위해 랜덤하게 일정 노드를 학습에 반영하지 않음\n",
    "    - Flatten : Dense 층에 연결 해주기 전 2차원 배열의 이미지를 1차원 배열로 바꾸어 줌\n",
    "- 라온피플 CNN : https://blog.naver.com/laonple/220624485850\n",
    "- CNN blog : https://taeu.github.io/cs231n/deeplearning-cs231n-CNN-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0475a4-94ac-4617-a88e-d1f5504e97fd",
   "metadata": {},
   "source": [
    "### CNN Process : Input - 특징 추출 - 처리기 - Output\n",
    "- 특징 추출 : Conv 층, Pooling, Dropout, ...\n",
    "- 처리기 : Flatten -> softmax ~ 다중분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ed891-1c8f-435f-bdca-053c75bf475c",
   "metadata": {},
   "source": [
    "### CNN 계열 모델 소개\n",
    "- VGGNet\n",
    "    - ILSVRC(ImageNet Large Scale Visual Recognition Challenge) : 이미지 인식(image recognition) 경진대회\n",
    "    - 경진대회 2위 모델이지만 타 모델에 비해 구조가 단순하여 응용이 쉽기 때문에 자주 쓰이는 모델\n",
    "    ![title](VGG16.png)\n",
    "    - 망의 깊이에 따라 모델 성능이 얼마나 개선되는지에 대한 연구 진행\n",
    "    - 3x3 kernel 크기 고정하여 사용 - 연산량이 적고 망이 깊어짐\n",
    "        - 3x3 kernel : 3x3 + 3x3 = 18개 parameter\n",
    "        - 5x5 kernel : 5x5 = 25개 parameter\n",
    "        - 두 kernel 모두 마지막 output 이미지는 3x3 사이즈지만 layer는 3x3 kernel이 2 layer\n",
    "    ![title](33KERNEL.png)\n",
    "![title](highlayer.png)\n",
    "- ResNet\n",
    "    - 단순히 망의 깊이만 늘리는 것에 한계점 발견 : Vanishing Gradient, Overfiiting\n",
    "    - 두 문제를 해결하기 위한 방법에 대한 연구 진행\n",
    "    - 1x1 kernel의 효과\n",
    "        - 이미지 특성을 보존하므로 채널 수를 원하는 만큼 늘리거나 줄이기 용이\n",
    "        - 다른 크기의 연산보다 심플한 연산이므로 해당 층은 적은 양의 연산 수행\n",
    "        - 원하는 채널 수, 심플한 연산으로 activation 함수를 거치며 비선형성 증가 ~ 특성 추출\n",
    "            - 선형성 ~ 상수 곱과 합으로 이루어진 단순한 구조\n",
    "            - 비선형성 ~ 여러가지 요인의 복잡한 식으로 input,output의 결과가 나오는 구조  \n",
    "            https://shu-e.tistory.com/entry/CAE-%EC%9E%85%EB%AC%B8-%EC%9A%A9%EC%96%B4-%EB%B9%84%EC%84%A0%ED%98%95%EC%84%B1Nonlinearity\n",
    "    - BottleNeck 구조 ~ 1x1 kernel의 활용\n",
    "        - http://funmv2013.blogspot.com/2016/09/resnet.html\n",
    "    - Residual : 깊은 망의 최적화, 늘어난 깊이를 활용한 정확도 개선\n",
    "        - 참고 : https://dataplay.tistory.com/25  \n",
    "        https://m.blog.naver.com/laonple/220793640991  \n",
    "        https://daeunginfo.blogspot.com/2020/03/neural-networks-resnetresidual-neural.html\n",
    "        - H(x) = x + \"F(x)\" : 총 출력 H(x)에서 x를 뺀 \"나머지\", 입력과 출력에서 생긴 \"차이\" \n",
    "        - Identity Shortcut : 입력단의 단순한 특성 + 뒷부분의 복잡한 특성을 더하여 다음 layer에 전달  \n",
    "            (identity ~ '입력값을 그대로 전달')\n",
    "        - x = H(x)라고 가정할 때 x -> H(x) 구조에서 x -> x + F(x) 구조로의 관점 변경\n",
    "            - F(x) -> 0으로 보내야한다는 학습 방향이 결정되는 효과(pre_conditioning) / F(x) = \"나머지\"(Residual) 역할\n",
    "            - 입력단 특성과 출력단 특성이 더해지며 Vanishing Gradient를 방지하는 효과\n",
    "        - Residual Mapping ( x != H(x)의 구조일때 논점)\n",
    "            - 연산이 '덧셈'이 추가되는 구조로 변경되어 단순해짐\n",
    "\n",
    "      \n",
    "- 대표 모델 간단 설명 참고 : https://deep-learning-study.tistory.com/215"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e22d5b-0113-43ed-ba78-4a793460e777",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 전이 학습\n",
    "- 만들어져있는 모델을 불러와 customizing\n",
    "- VGGNet input : 224x224 / Output : 1000개 카테고리 분류\n",
    "- 사용 이미지 사이즈에 맞도록 input과 카테고리 분류 개수에 맞도록 output을 조절\n",
    "\n",
    "### Colab ~ GPU 사용\n",
    "- from google.colab import drive  \n",
    "  drive.mount('/content/gdrive')\n",
    "- https://funfunfuhaha.tistory.com/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2f895-e8da-4c32-b719-4a8ccca6439c",
   "metadata": {},
   "source": [
    "## 실습 데이터\n",
    "- 제조 공정 : 충진 공정에서 저울에 표기된 무게를 OCR로 파악\n",
    "- 철가루를 무게추에 채우는 과정으로 현장 오염도로 인해 노이즈가 심함→ 일반적인 OCR 모듈로 쉽게 인식되지 않음\n",
    "- 데이터 분석 목적 : 무게 입력 과정의 자동화 구현\n",
    "\n",
    "![title](OCR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc148d28-b1a5-410d-8478-eda366875c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2daf4-1cb1-4d33-b7e1-a3b7f44ff2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(rescale = 1./255, validation_split=0.2)\n",
    "\n",
    "train_dataset = image_generator.flow_from_directory(batch_size=32,\n",
    "                                                 directory='digit_data',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(280, 280), \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_dataset = image_generator.flow_from_directory(batch_size=32,\n",
    "                                                 directory='digit_data',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(280, 280), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "# https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e314f-3cfb-4050-bf0e-897ce41291ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(280, 280, 3), dtype='float32', name='input')\n",
    "\n",
    "#vgg16 모델 불러오기\n",
    "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(280, 280, 3))\n",
    "pre_trained_vgg.trainable = False\n",
    "pre_trained_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02c8bd-e385-4f7a-836d-b59cc64b1b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vgg16 밑에 fc 층 연결\n",
    "x = pre_trained_vgg.output\n",
    "x = layers.Flatten()(x) # fc층 이전 flatten\n",
    "x = layers.Dense(8192, activation='relu')(x) # (8,8,512) -> 32768 / 4 = 8192\n",
    "x = layers.Dense(2048, activation='relu')(x) # 8192 / 4 = 2048\n",
    "x = layers.Dense(512, activation='relu')(x) # 2048 / 4 = 512 \n",
    "output = layers.Dense(10, activation='softmax')(x) # 최종 클래스 10개\n",
    "\n",
    "model = Model(pre_trained_vgg.input, output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.00001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4acd03-2e31-4938-a51f-e98f8a41ec5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ee509-b8f8-44ae-8796-01c746fae112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colab에서 실행\n",
    "# model.fit_generator(train_dataset, steps_per_epoch = 300, epochs = 100,\n",
    "#                     validation_data = validation_dataset, validation_steps = 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
